# iHub - AI Companion WebGL Integration

An interactive AI companion application built with React + Vite that embeds a Unity WebGL animated character. The companion responds to user interactions with expressive animations, emotion triggers, and real-time lip-sync, creating an engaging virtual assistant experience.

## ğŸ¤– What is This?

This is an **AI companion web application** featuring:
- **Interactive 3D Character** - Unity WebGL character (Epsilon) with emotion-based animations
- **Real-time Communication** - Bidirectional messaging between web UI and Unity runtime
- **Audio Processing** - Upload audio files or stream voice input with automatic lip-sync
- **Emotion Triggers** - Send emotion states (embarrassed, happy, sad, etc.) to animate the character
- **Voice Visualization** - Real-time mouth movement synced to audio volume analysis

Perfect for building virtual assistants, chatbots with visual presence, educational companions, or interactive storytelling experiences.

## ğŸ¯ Features

- âœ¨ **Full-screen 3D character background** - Seamlessly integrated Unity WebGL build
- ğŸ­ **Emotion-based animations** - Trigger character expressions and poses
- ğŸ¤ **Audio upload & processing** - Browser-based audio decoding and analysis
- ğŸ‘„ **Real-time lip-sync** - Mouth movements synced to audio volume (RMS analysis)
- ğŸ”„ **Live communication** - React UI controls Unity character in real-time
- ğŸ¨ **Modern UI** - Tailwind CSS overlay controls with backdrop blur

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          React App (UI Layer)          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   App.jsx   â”‚  â”‚  AudioSender.jsx â”‚ â”‚
â”‚  â”‚  (Triggers) â”‚  â”‚  (Audio + Volume)â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                   â”‚           â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                 â–¼                       â”‚
â”‚      window.__unityBgInstance          â”‚
â”‚         (SendMessage Bridge)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Unity WebGL Build (Canvas)        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  GameObject: "Epsilon"          â”‚   â”‚
â”‚  â”‚  - TriggerByName(string)        â”‚   â”‚
â”‚  â”‚  - UpdateMouthVolume(string)    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  GameObject: "WebGLInputManager"â”‚   â”‚
â”‚  â”‚  - PlayAudioFromJS(string json) â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Getting Started

### Prerequisites

- Node.js 18+ and npm
- Unity WebGL build files in `model/Build/`

### Installation

```bash
# Install dependencies
npm install

# Run development server
npm run dev

# Build for production
npm run build

# Preview production build
npm run preview
```

### Development

The app will be available at `http://localhost:5173` (or the port shown in terminal).

## ğŸ“ Project Structure

```
ihub/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.jsx                    # React entry point
â”‚   â”œâ”€â”€ App.jsx                     # Main app with trigger UI
â”‚   â”œâ”€â”€ index.css                   # Tailwind imports
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ ModelBackground.jsx     # Unity WebGL loader & canvas
â”‚   â”‚   â””â”€â”€ AudioSender.jsx         # Audio upload & processing
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ audioPipeline.js        # Audio utilities (if present)
â”œâ”€â”€ model/
â”‚   â””â”€â”€ Build/                      # Unity WebGL build files
â”‚       â”œâ”€â”€ model.loader.js         # Unity loader script
â”‚       â”œâ”€â”€ model.framework.js      # Unity framework (wasm glue)
â”‚       â”œâ”€â”€ model.wasm              # WebAssembly binary
â”‚       â””â”€â”€ model.data              # Unity asset bundle
â”œâ”€â”€ public/
â”‚   â””â”€â”€ webglAudioResume.js         # Audio autoplay policy handler
â””â”€â”€ package.json
```

## ğŸ”§ Key Components

### `ModelBackground.jsx`
Loads and initializes the Unity WebGL build:
- Dynamically injects Unity loader script
- Creates Unity instance from canvas
- Exposes instance globally as `window.__unityBgInstance`
- Handles cleanup on unmount

### `App.jsx`
Main UI for sending triggers to Unity:
- Text input for custom trigger names
- Sends messages to Unity GameObject `"Epsilon"` via `TriggerByName(string)` method
- Includes `AudioSender` component

### `AudioSender.jsx`
Audio file processing and streaming:
- Decodes audio files using Web Audio API
- Sends raw audio samples to Unity as JSON
- Computes real-time RMS volume from audio
- Sends volume updates to Unity for mouth animation sync

## ğŸ”Œ Unity Integration

### Required Unity GameObjects & Methods

Your Unity scene must have these GameObjects with corresponding methods:

#### GameObject: `"Epsilon"`
```csharp
public class CharAnim : MonoBehaviour
{
    // Receives trigger strings from React
    public void TriggerByName(string triggerName)
    {
        // Handle animation trigger
        Debug.Log($"Received trigger: {triggerName}");
    }
    
    // Receives volume values for lip-sync (sent as string)
    public void UpdateMouthVolume(string volumeStr)
    {
        float volume = float.Parse(volumeStr);
        // Update mouth blend shape or animation parameter
    }
}
```

#### GameObject: `"WebGLInputManagerGameObject"`
```csharp
[System.Serializable]
public class AudioData
{
    public float[] samples;
    public int sampleRate;
}

public class WebGLInputManager : MonoBehaviour
{
    // Receives audio data as JSON string
    public void PlayAudioFromJS(string json)
    {
        AudioData data = JsonUtility.FromJson<AudioData>(json);
        // Process audio samples (data.samples, data.sampleRate)
    }
}
```

## ğŸ“¡ Communication Flow

### Sending Triggers
```javascript
// From React/JS
window.__unityBgInstance.SendMessage(
    'Epsilon',           // GameObject name
    'TriggerByName',     // Method name
    'embarrassedtrigger' // String parameter
);
```

### Sending Audio
```javascript
// From React/JS
const audioData = {
    samples: Array.from(float32Array),
    sampleRate: 48000
};
window.__unityBgInstance.SendMessage(
    'WebGLInputManagerGameObject',
    'PlayAudioFromJS',
    JSON.stringify(audioData)
);
```

### Sending Volume (Real-time)
```javascript
// From React/JS (called every animation frame)
window.__unityBgInstance.SendMessage(
    'Epsilon',
    'UpdateMouthVolume',
    volume.toString() // 0.0 - 1.0
);
```

## âš ï¸ Common Issues & Solutions

### Unity Instance Not Ready
**Problem:** `SendMessage` called before Unity loads  
**Solution:** Check `window.__unityBgInstance` exists before calling

### GameObject Not Found
**Problem:** Messages not reaching Unity  
**Solution:** Verify GameObject names match exactly (case-sensitive)

### Large Audio Files
**Problem:** JSON.stringify of large Float32Arrays is slow  
**Solution:** Chunk audio or send downsampled data

### Audio Not Playing
**Problem:** Browser autoplay policy blocks audio  
**Solution:** Ensure user interaction (click) before creating AudioContext

### CORS / 404 Errors
**Problem:** Unity build files not loading  
**Solution:** Verify files exist in `/model/Build/` and dev server serves them

## ğŸ¨ Tech Stack

- **React 19** - UI framework
- **Vite 7** - Build tool and dev server
- **Tailwind CSS 4** - Styling
- **Unity WebGL** - Character rendering and animation
- **Web Audio API** - Audio processing and analysis

## ğŸ” Configuration

### Unity Build Settings
Ensure your Unity build exports these files:
- `model.loader.js`
- `model.framework.js`
- `model.wasm`
- `model.data`

### GameObject Names
Update these constants in your code if Unity uses different names:
```javascript
// In App.jsx
const goName = 'Epsilon';  // Change to match your GameObject

// In AudioSender.jsx
const audioGO = 'WebGLInputManagerGameObject';  // Change if needed
```

## ğŸ§ª Testing

```bash
# Lint code
npm run lint

# Type check (if using TypeScript)
# npm run type-check
```

## ğŸ“ Notes

- This is an **AI companion interface** - the character can be integrated with LLM APIs for conversational AI
- Unity `SendMessage` only accepts string parameters by default
- Complex data (arrays, objects) must be sent as JSON and parsed in Unity
- Audio context may be suspended until user interaction (browser policy)
- Large audio payloads can impact performance - consider chunking or compression
- The companion character (Epsilon) can display various emotional states through animation triggers

## ğŸš€ Future Enhancements

- [ ] Integrate with OpenAI/Anthropic APIs for conversational responses
- [ ] Add text-to-speech (TTS) for AI-generated audio
- [ ] Implement speech-to-text (STT) for voice input
- [ ] Add emotion detection from text sentiment
- [ ] WebSocket connection for real-time AI streaming responses
- [ ] Background environment picker
- [ ] Multiple character models
- [ ] Gesture and pose controls

## ğŸ’¡ Use Cases

- **Virtual Assistants** - Customer support with a friendly face
- **Educational Companions** - Interactive tutors for e-learning
- **Healthcare** - Mental health support companions
- **Entertainment** - Interactive storytelling and gaming NPCs
- **Accessibility** - Visual interface for voice-based AI services

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Open a Pull Request


**Need Help?** Check the browser console for Unity loader errors and `SendMessage` logs.
